{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "169ce4b5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a039b4d1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Learning\n",
    "* Enables problem solving:\n",
    "    * the transition of a state with respect to a quality factor\n",
    "    * state x is changed with some function\n",
    "    * f(speech) = emotion\n",
    "    * f(x) = x'\n",
    "    * e.g. f(x) = a x + b\n",
    "    * find a and b so that x' is optimal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed57455",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Terminology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d26e52d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Loss function\n",
    " is the function that artificial neural nets use to track progress, i.e. the function that evaluates the predicted outcome with the desired one. Finding a good loss function is crucial for your task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87be2d0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Backpropagation\n",
    "Fundamental way to train neural networks by evaluating the error with the loss function and than propagating it backwards towards the input layer, by taking the derivative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f616679",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Batch size\n",
    "number of samples in one batch in the training which are used together to compute the error (-> loss function) and do the backpropagation step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc6b464",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Embeddings\n",
    " are learned representations of data, usually the pen-ultimate layer of a pretrained artificial neural net. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423b215c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Latent space\n",
    " means the property of deep artificial neural nets to represent specific features of the data within the higher layers, for example speaker characteristics or expressed emotion in a net trained for speech synthesis. This is often used to influence the output in a desired way, for example simulating a specific speaking style."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d6cf51",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Freezing\n",
    " layers in an ANN means to not update the weights, as they might contain knowledge that should not be forgotten (from a pretrained net) or to make the training faster.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5be0ac",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Drop out\n",
    "is the technique to delete a number of randomly selected neurons in a hidden layer during training to prevent [overfitting](http://blog.syntheticspeech.de/2022/02/16/kinds-of-machine-learning/#Overfitting)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2133df",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Patience \n",
    "* Number of epochs with no improvement after which training will be stopped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cc3eeb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Overfitting\n",
    "* Means that the machine learner performs well on the training but not on any other data. \n",
    "* This is usually the case when the model has enough complexity to distinguish all training data and is trained for enough periods (one period is one run through the training). \n",
    "* Measures against this are subsumed under the label *regularization*. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461fbd54",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Vanishing / exploding gradient \n",
    "Means that the weights of the neurons become too small or too large for the net to be stable. \n",
    "\n",
    "This happens especially with very deep (many layers) networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5819ac51",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Bias vs. variance \n",
    " means the trade-off between generalization (high bias, underfitting) and specification (high variance, overfitting). You can either \n",
    " \n",
    "* have simple models, like e.g. linear regression classifiers, that will treat every input with a similar strong bias (wrong decisions), irrespective of the training set, or \n",
    "* very complex models (e.g. a neural net with many layers) that will be more exact but very specific to your training data.\n",
    "\n",
    "[Here](https://mlu-explain.github.io/bias-variance/)'s a nice visualization of bias vs. variance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f465730d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How to split your data\n",
    "In supervised machine learning, you usually need three kinds of data sets:\n",
    "* train data: to teach the model the relation between data and labels\n",
    "* dev data: (short for *development*) to tune meta parameters of your model, e.g. \n",
    "    * *number of neurons*, \n",
    "    * *batch size* or \n",
    "    * *learning rate*.\n",
    "* test data: to evaluate your model ONCE at the end to check on generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118e5047",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Of course all this is to prevent [*overfitting*](http://blog.syntheticspeech.de/2022/02/16/kinds-of-machine-learning/#Overfitting) on your train and/or dev data.\n",
    "\n",
    "If you've used your test data for a while, \n",
    "you might need to find a new set, \n",
    "as chances are high that you overfitted \n",
    "on your test during experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32991ced",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So what's a good split?\n",
    "\n",
    "Some rules apply:\n",
    "* train and dev can be from the same set, but the test set is ideally from a different database.\n",
    "* if you don't have so much data, a 80/20/20 % split is normal\n",
    "* if you have masses an data, use only so much dev and test that your population seems covered.\n",
    "* If you have really little data: use [x cross validation](http://blog.syntheticspeech.de/2022/11/28/how-to-evaluate-your-model/#X_fold_cross_validation) for train and dev, still the test set should be extra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b56745",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Nkululeko exercise 1\n",
    "\n",
    "\n",
    "Edit the [demo configuration](https://github.com/felixbur/nkululeko/blob/main/demos/exp_emodb.ini)\n",
    "\n",
    "Set/keep as target *emotion* as FEAT type *os* and as MODEL type *xgb*\n",
    "\n",
    "Use the emodb as test and train set but try [out all split methods](https://github.com/felixbur/nkululeko/blob/main/ini_file.md#data)\n",
    "* specified\n",
    "* speaker split\n",
    "* random\n",
    "* loso\n",
    "* logo \n",
    "* 5_fold_cross_validation\n",
    "\n",
    "Which works best and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02da536c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Nkululeko exercise 2\n",
    "Set the \n",
    "```\n",
    "[EXP]\n",
    "epochs = 200\n",
    "[MODEL] \n",
    "type = mlp\n",
    "layers = {'l1':1024, 'l2':64} \n",
    "save = True\n",
    "[PLOT]\n",
    "epoch_progression = True\n",
    "best_model = True\n",
    "```\n",
    "run the experiment.\n",
    "Find the epoch progression plot and see at which epoch overfitting starts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170c4f94",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Evaluation\n",
    "This post is about evaluation of machine learning models, obviously the answer to the question if a model is any good depends a lot on how you test that.\n",
    "\n",
    "## Criteria\n",
    "Depending whether you got a classification or regression problem you can choose from a multitude of measures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db3ab49",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Classification\n",
    "Most of these measures are derived from the confusion matrix:\n",
    "* **Confusion Matrix** : Matrix with results: rows represent the real values and columns the predictions. \n",
    "* In the binary case, the cells are called *True Positive* (TP), *False Negative* (FN: Type 2 error), *False Positive* (FN: Type 1 error) and *True Negative* (TN)\n",
    "\n",
    "<img src=images/Prec-recall.png width=20%>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
