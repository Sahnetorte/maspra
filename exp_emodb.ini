[EXP]
root = ./results/
name = emodb
epochs = 20
[DATA]
databases = ['emodb']
emodb = ./data/emodb/
emodb.split_strategy = specified
emodb.train_tables = ['emotion.categories.train.gold_standard']
emodb.test_tables = ['emotion.categories.test.gold_standard']
target = emotion
labels = ['anger', 'boredom', 'disgust', 'fear', 'happiness', 'neutral', 'sadness']
[FEATS]
# use a transformer pretrained neural net as acoustic features
#type = ['wav2vec2-large-robust-ft-swbd-300h']
# use the opensmile acoustic features
type = ['os']
# use acoustic features extracted with Praat software and select some of them
#type = ['praat']
#features = ['stdevF0Hz', 'meanF0Hz', 'speechrate(nsyll / dur)']
# use the transformer model, but finetuned on emotional data
#type = ['audmodel']
store_format = csv
#features = ['speechrate(nsyll / dur)', 'meanF0Hz']
scale = standard
[MODEL]
type = mlp
layers = {'l1':128, 'l2':16}
device = cuda
save = True
[EXPL]
scatter = ['pca']
#spotlight = True
[PLOT]
best_model = True
epoch_progression = True
