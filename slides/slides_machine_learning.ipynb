{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "169ce4b5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a039b4d1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Learning\n",
    "* Enables problem solving:\n",
    "    * the transition of a state with respect to a quality factor\n",
    "    * state x is changed with some function\n",
    "    * f(speech) = emotion\n",
    "    * f(x) = x'\n",
    "    * e.g. f(x) = a x + b\n",
    "    * find a and b so that x' is optimal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f465730d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How to split your data\n",
    "In supervised machine learning, you usually need three kinds of data sets:\n",
    "* train data: to teach the model the relation between data and labels\n",
    "* dev data: (short for *development*) to tune meta parameters of your model, e.g. \n",
    "    * *number of neurons*, \n",
    "    * *batch size* or \n",
    "    * *learning rate*.\n",
    "* test data: to evaluate your model ONCE at the end to check on generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118e5047",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Of course all this is to prevent [*overfitting*](http://blog.syntheticspeech.de/2022/02/16/kinds-of-machine-learning/#Overfitting) on your train and/or dev data.\n",
    "\n",
    "* If you've used your test data for a while, \n",
    "you might need to find a new set, \n",
    "as chances are high that you overfitted \n",
    "on your test during experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32991ced",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So what's a good split?\n",
    "\n",
    "Some rules apply:\n",
    "* train and dev can be from the same set, but the test set is ideally from a different database.\n",
    "* if you don't have so much data, a 80/10/10 % split is normal\n",
    "* if you have masses an data, use only so much dev and test that your population seems covered.\n",
    "* you can stratify the data\n",
    "* If you have really little data: use [x cross validation](http://blog.syntheticspeech.de/2022/11/28/how-to-evaluate-your-model/#X_fold_cross_validation) for train and dev, still the test set should be extra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b56745",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Nkululeko exercise 1\n",
    "\n",
    "\n",
    "Edit the [demo configuration](https://github.com/felixbur/nkululeko/blob/main/demos/exp_emodb.ini)\n",
    "Set/keep as target *emotion* as FEAT type *os* and as MODEL type *xgb*\n",
    "Use the emodb as test and train set but try [out all split methods](https://github.com/felixbur/nkululeko/blob/main/ini_file.md#data)\n",
    "* specified\n",
    "* speaker split\n",
    "* balanced\n",
    "* random\n",
    "* loso\n",
    "* logo \n",
    "* 5_fold_cross_validation\n",
    "\n",
    "Which works best and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02da536c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Nkululeko exercise 2\n",
    "Set the \n",
    "```\n",
    "[EXP]\n",
    "epochs = 200\n",
    "[MODEL] \n",
    "type = mlp\n",
    "layers = {'l1':1024, 'l2':64} \n",
    "save = True\n",
    "[PLOT]\n",
    "epoch_progression = True\n",
    "best_model = True\n",
    "```\n",
    "run the experiment.\n",
    "Find the epoch progression plot and see at which epoch overfitting starts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170c4f94",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Evaluation\n",
    "These slides about evaluation of machine learning models, obviously the answer to the question if a model is any good depends a lot on how you test that.\n",
    "\n",
    "## Criteria\n",
    "Depending whether you got a classification or regression problem you can choose from a multitude of measures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db3ab49",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Classification\n",
    "Most of these measures are derived from the confusion matrix:\n",
    "* **Confusion Matrix** : Matrix with results: rows represent the real values and columns the predictions. \n",
    "* In the binary case, the cells are called *True Positive* (TP), *False Negative* (FN: Type 2 error), *False Positive* (FN: Type 1 error) and *True Negative* (TN)\n",
    "* So in the example (next slide), TP=3, FN=4, FP=3 and TN=3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6636f722",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=images/Prec-recall.png width=40%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e70065",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=images/conf_mat.png width=40%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ea47d2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The following measurements can be derived from these:\n",
    "\n",
    "* **Accuracy**: Percentage of correct predictions -> (TP+TN)/(TP+FP+FN+TN).\n",
    "* **un- / weighted Recall/Sensitivity**: percentage of detected cases -> TP / (TP+FN). Can be weighted by class frequency, for multiple classes \n",
    "* **un- / weighted Precision**: percentage of relevant predictions -> TP / (TP+FP)\n",
    "* **Specificity**: Like sensitivity, but for the negative examples -> TN / (TN+FP)\n",
    "* **F1**: Combination of Recall and Precision -> F1 = 2 * (Rec* Prec)/ (Rec + Prec) \n",
    "* **AUC/ROC** Usually there's a tradeoff between Recall and Precision. With the *Receiver Operator Curve*  and it's *Area under curve* this can be visualized by plotting the False positive rate (100-specificity) against the True positive rate (sensitivity)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89b8dfa",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Regression\n",
    "* **Pearson's** Pearson's Correlation Coefficient  measures the similarity of two sets of numbers with the same lenght. I's a value between -1 and 1, with 0 meaning no correlation and -1 negative correlation. When plotted in 2-d space, PCC=1 would be the identity line.\n",
    "\n",
    "* **MAE** Mean absolute error: taken two sets of numbers with same length as correct and predicted values, one can compute the mean absolute error by summing up the absolute values of the pairwise differences and scale by the number of samples.\n",
    "* **MSE** Mean squared error\n",
    "* **CCC** Concordance Correlation Coefficient is a measure quite similar to PCC but tries to penalize rater bias (seeing the two distributions as truth and ratings)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdc54d6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Approaches\n",
    "### Train / test /dev splits\n",
    "Best you have enough data to split it into seperate sets:\n",
    "* **train** for the training\n",
    "* **dev** (or **eval**): to tune meta-parameters\n",
    "* **test** as a final test set \n",
    "\n",
    "Be careful to make sure that they are  speaker disjunct, i.e. not have overlapping speakers, else you can't be sure if you learn general speaker characteristics or speaker idiosyncrasies.\n",
    "\n",
    "Also it's a very good idea to have the test set from a completely different data source, so you could have more trust in the generalizability of your model.\n",
    "\n",
    "More [on the subject here](http://blog.syntheticspeech.de/2022/12/01/how-to-split-you-data/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d73ef57",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### X fold cross validation\n",
    "\n",
    "* If you are low on data, you might try x fold cross validation, \n",
    "* it means that you split your data  in *x* (usually 10) sets with same size, \n",
    "* and then do *x* trainings, \n",
    "* using one set as *dev set* and the rest for *train*.\n",
    "\n",
    "**Nkululeko exercise**: try this with the MODEL k_fold_cross option"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc46a1b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### LOSO\n",
    "\n",
    "* *Leave one Speaker out* \n",
    "* is like X fold cross-validation, but each set are all samples of one speaker. \n",
    "* If there are many speakers, you might want *Leave one speaker group out*.\n",
    "Both is supported by [Nkululeko](http://blog.syntheticspeech.de/2021/08/04/machine-learning-experiment-framework/).\n",
    "\n",
    "**Nkululeko exercise**: try this with the MODEL logo option"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df1151c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Meta parameter tuning\n",
    "* The parameters that configure machine learning algorithms are called *meta parameters* \n",
    "* in contrast to the \"normal\" *parameters* that are learned during training.\n",
    "* But as they obviously also influence the quality of your predictions, these parameters also must be learned.\n",
    "* They are *optimized* on the *dev-set*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4f43a8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Examples are \n",
    "    * the C parameter for SVM\n",
    "    * the number of subsamples for XGB\n",
    "    * the number of layers and neurons for a neural net\n",
    "\n",
    "* The naive approach is simply to try them all, systematically,\n",
    "but this does not scale.\n",
    "\n",
    "* In general, because the search space for the optimal configuration usually is without limit, it'd be better to try a stochastic approach or a genetic one.\n",
    "\n",
    "**Nkululeko exercise**: optimize the parameters [using *tuning_params*](http://blog.syntheticspeech.de/2021/09/03/perform-optimization-with-nkululeko/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9382c3b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data augmentation\n",
    "* Often (kind of always) there is a lack of training data for supervised learning.\n",
    "* One way to tackle this is representation learning which can be done in an self-supervised fashion.\n",
    "* Another approach is to multiply your labeled training data by adding slightly altered versions of it, \n",
    "* that would not change the information that is the aim of the detection, \n",
    "    * for example by adding noise to the data or clipping it.\n",
    "    \n",
    "**Nkululeko exercise**: try this with the [*augment* module](http://blog.syntheticspeech.de/2023/03/13/nkululeko-how-to-augment-the-training-set/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1a0572",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* A third way is to synthesize data based on the labeled training, \n",
    "* for example with GANs, VAEs or with rule-based simulation. \n",
    "* It can be distinguished if in this case only a parameterized for of the samples (ie. the features) or raw samples are generated.\n",
    "\n",
    "* Sometimes only samples for a rare class are needed, \n",
    "    * in this case techniques like ROS (random over sampling), \n",
    "    * Synthetic Minority Oversampling Technique (SMOTE) or the \n",
    "    * Adaptive Synthetic (ADASYN) can be used.\n",
    "    \n",
    "**Nkululeko exercise**: try this with the [FEATS balancing key](http://blog.syntheticspeech.de/2023/11/16/nkululeko-oversample-the-training-set/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7116ed0c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Feature normalization\n",
    "* \"Normalizing\" or scaling feature values means \n",
    "* to shift them to a common range, or distribution with same mean and standard deviation \n",
    "    * (also called z-transformation).\n",
    "* You would do that for several reasons:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db629f7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Artificial neural nets can handle small numbers best, so they all should be in the range -1, 1\n",
    "* Speakers have their individual ways to speak which you are not interested in if you want to learn a general task, e.g. emotion or age. So you would speaker-normalize the values for each speaker individually. Of course this is in most applications not possible because you don't have already samples of your test speakers.\n",
    "* You might want to normalize the sexes, because woman typicall have a higher pitch. But another way out is also to use only relative values and not absolute ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a90ec4f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Mind that you shouldn't use your test set for normalization \n",
    "* as it really only should be used for test and is supposed to be unknown. \n",
    "* That's why you should compute your normalization parameters on the training set, you can then use them to normalize/scale the test.\n",
    "\n",
    "**Nkululeko exercise**: try this with the [FEATS scaling key](http://blog.syntheticspeech.de/2021/03/26/feature-scaling/)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
