[EXP]
root = ./results/
name = emodb
epochs = 20
[DATA]
databases = ['emodb']
emodb = ./databases/emodb/
emodb.split_strategy = specified
emodb.train_tables = ['emotion.categories.train.gold_standard']
emodb.test_tables = ['emotion.categories.test.gold_standard']
target = emotion
labels = ['anger', 'boredom', 'disgust', 'fear', 'happiness', 'neutral', 'sadness']
[FEATS]
# use a transformer pretrained neural net as acoustic features
#type = ['wav2vec2-large-robust-ft-swbd-300h']
# use the opensmile acoustic features
#type = ['os']
# use acoustic features extracted with Praat software and select some of them
type = ['praat']
features = ['stdevF0Hz', 'meanF0Hz', 'speechrate_nsyll_dur']
# use the transformer model, but finetuned on emotional data
#type = ['audmodel']
store_format = csv
scale = standard
[MODEL]
type = mlp
layers = {'l1':128, 'l2':16}
device = cuda
save = True
[EXPL]
scatter = ['pca', 'umap']
scatter.dim = 3
#spotlight = True
[PLOT]
best_model = True
epoch_progression = True
